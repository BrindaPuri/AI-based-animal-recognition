# -*- coding: utf-8 -*-
"""ResNet Cal Data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eelh8G9zLGOjnaqM6V_soL8mh01WEfYx

Importing required libries
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import PIL
from sklearn.model_selection import train_test_split
import pathlib
import shutil
import cv2
import torch
from torchvision import transforms
import glob
import string
import torchvision

def PlotDataRep_Bar(df):
  plt.figure(figsize = (20,15))
  fg = sns.countplot(x = df['original_label'])
  for p in fg.patches:
   fg.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))
  fg.set_title("Count Plot of Classes")
  fg.set_xlabel("Label number")
  fg.set_ylabel("Number of Animals")

def PlotDataRep_Pie(df):
  plt.pie(df['original_label'].value_counts(), labels=df.original_label.unique(),autopct="%0.1f")
  plt.show()

"""Importing labels from image net"""

# Download ImageNet labels
!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

"""Initilizing list of images in folder"""

file_names=os.listdir("/content/drive/Shareddrives/193/Camera Data/Caltech_Camera_Traps/eccv_18_all_images_sm")
folder_size=len(file_names)
print(folder_size)

"""Creating Dataframe from labeled csv for data analysis"""

csv_dir="/content/drive/Shareddrives/193/Code/Brinda/CalCal_filtered_dataset_dataset.csv"
df = pd.read_csv(csv_dir)
image_id = df.image_id
label=df.original_label
df=df.drop(columns=['Unnamed: 0'])
df

data_dir = pathlib.Path("/content/drive/Shareddrives/193/Camera Data/Caltech_Camera_Traps")
names=[]
for img_name in data_dir.glob('eccv_18_all_images_sm/*'):
  head, tail = os.path.split(img_name)
  names.append(tail)

len(names)

isFile=os.path.isfile(path+'5a2e14d4-23d2-11e8-a6a3-ec086b02610b.jpg')
print(isFile)

#print(len(names)) #57873

len(df)# still some extra values 62643

"""Unique Labels"""

df.groupby('original_label').count()

PlotDataRep_Bar(df) # after filtering non animals

"""Dropping data with label car and empty as it should be filtered out by Object Detection"""

print(df.original_label.unique())

# storing path
path = '/content/drive/Shareddrives/193/Camera Data/Caltech_Camera_Traps/eccv_18_all_images_sm/'
data_dir = pathlib.Path("/content/drive/Shareddrives/193/Camera Data/Caltech_Camera_Traps")
# Check whether a path pointing to a file
isFile=os.path.isfile(path+'59974040-23d2-11e8-a6a3-ec086b02610b.jpg')
print(isFile)

img = list(data_dir.glob('eccv_18_all_images_sm/*'))  # list of image from folder

data_dir = pathlib.Path("/content/drive/Shareddrives/193/Camera Data/Caltech_Camera_Traps")
names=[]
for img_name in data_dir.glob('eccv_18_all_images_sm/*'):
  head, tail = os.path.split(img_name)
  names.append(tail)

print("number of entries in df =",len(image_id),"\nnumber of in folder images =",len(img)) # list image names from df

len(img)/len(image_id)

#storing df to json 
#df.to_json(r'/content/drive/Shareddrives/193/Code/Brinda/Cal_filtered_dataset.json')
#df.to_csv(r'/content/drive/Shareddrives/193/Code/Brinda/CalCal_filtered_dataset_dataset.csv')

#calling an opening a image
IMG_NO=3
print(img[IMG_NO])
PIL.Image.open(str(img[IMG_NO]))

"""Train and Test Split using df image_id"""

image_id_train,image_id_test,label_train,label_test = train_test_split(image_id,label,test_size=0.2)

count = 0
subset_train= []
label_train=[]
for labl in label_train:
  count = count +1
  subset_train.append(labl)
  if count == 1000:
    break
count = 0
for image in image_id_train:
  count = count +1
  subset_train.append(image)
  if count == 1000:
    break

print(len(subset_train))

#creating classes
for i in df.original_label.unique():
  os.makedirs("/content/Train/"+ i)
  #os.makedirs("/content/Test/"+ i)

l=df.index[df['image_id']=="59b93a3b-23d2-11e8-a6a3-ec086b02610b.jpg"].tolist()

print(l)

for name in subset:
  isFile=os.path.isfile(path+name)
  l=df.index[df['image_id']==name]
  lab=list(label[l])[0]
  if(isFile):
    shutil.copy(path+name, "/content/Train/"+lab+"/"+name)

!zip -r /content/sample_data.zip /content/sample_data

"""Running on single image"""

resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)
resnet.trainable = False
# activating the evaluation mode after this we can feed the input
resnet.eval()

def transform_img(img):
  transform = transforms.Compose([
  transforms.Resize(700),
  transforms.CenterCrop(700),
  transforms.ToTensor(),
  transforms.Normalize(mean = [0.485, 0.456, 0.406],
  std = [0.229, 0.224, 0.225])
  ]) 
  Transformed_inputImage=transform(img)
  print(Transformed_inputImage.shape)
  return Transformed_inputImage

im = tf.keras.preprocessing.image.load_img(img[IMG_NO])
im=transform_img(im)

InputImg_batched = torch.unsqueeze(im, 0)

out = resnet(InputImg_batched)

with open('/content/imagenet_classes.txt') as f:
  labels = [line.strip() for line in f.readlines()]

_, predicted = torch.max(out, 1)
percentage = torch.softmax(out, dim = 1)[0] * 100
print(labels[predicted[0]], percentage[predicted[0]].item())

"""https://vitalflux.com/pytorch-load-predict-pretrained-resnet-model/

Training set of images
"""

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Set hyperparameters
num_epochs = 5
batch_size = 4
learning_rate = 0.001

# Initialize transformations for data augmentation
transform = transforms.Compose([
    transforms.Resize(700),
    transforms.CenterCrop(700),
    #transforms.RandomHorizontalFlip(),
    #transforms.RandomVerticalFlip(),
    #transforms.RandomRotation(degrees=45),
    #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),
    #transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])])

# Load the ImageNet Object Localization Challenge dataset
train_dataset = torchvision.datasets.ImageFolder(
    root='/content/Train', 
    transform=transform
)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

# Load the ResNet50 model
model = torchvision.models.resnet50(weights=True)

# Parallelize training across multiple GPUs
model = torch.nn.DataParallel(model)

# Set the model to run on the device
model = model.to(device)

# Define the loss function and optimizer
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Train the model...
for epoch in range(10):
    for inputs, labels in train_loader:
        # Move input and label tensors to the device
        inputs = inputs.to(device)
        labels = labels.to(device)

        # Zero out the optimizer
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward pass
        loss.backward()
        optimizer.step()

    # Print the loss for every epoch
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')

print(f'Finished Training, Loss: {loss.item():.4f}')

!mkdir models
!mkdir models/pytorch
torch.save(model.state_dict(), '/content/models/pytorch/model_weights.pth')

model.load_state_dict(torch.load('/content/models/pytorch/model_weights.pth'))
model.eval()
#https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html

#creating classes
for i in df.original_label.unique():
  #os.makedirs("/content/Train/"+ i)
  os.makedirs("/content/Test/"+ i)

img_predict = model.fit(image_id_train, label_train).predict(image_id_test)